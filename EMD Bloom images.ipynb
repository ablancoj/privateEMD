{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric searchable encyption for reverse image search (only index)\n",
    "\n",
    "#### Bloom filter implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T22:18:26.375648Z",
     "start_time": "2020-05-02T22:18:26.304714Z"
    }
   },
   "outputs": [],
   "source": [
    "import hmac\n",
    "from base64 import urlsafe_b64encode\n",
    "from hashlib import sha512\n",
    "from math import floor, log\n",
    "from bitarray import bitarray\n",
    "\n",
    "def expand(func):\n",
    "    return [bytes('({}-{})'.format(i+1, c), encoding='ascii') for i, x in enumerate(func) for c in range(1, x+1)]\n",
    "\n",
    "def comparesets(a, b, m, k, pin, repeats=0):\n",
    "    bfa = BloomFilter(m, k, pin)\n",
    "    bfb = BloomFilter(m, k, pin)\n",
    "    bfa.addall(a)\n",
    "    bfb.addall(b)\n",
    "    return bfa.jaccard_distance(bfb)\n",
    "\n",
    "def comparefunctions(f, g, m, k, pin):\n",
    "    bff = BloomFilter(m, k, pin)\n",
    "    bfg = BloomFilter(m, k, pin)\n",
    "    bff.addall(expand(f))\n",
    "    bfg.addall(expand(g))\n",
    "    result = 2*bff.union_encoded_estimate(bfg) - bff.encoded_estimate() - bfg.encoded_estimate()\n",
    "    return result\n",
    "\n",
    "class BloomFilter(object):\n",
    "    def __init__(self, m=1024, k=1, pin=b'0'):\n",
    "        self.m = m\n",
    "        self.k = k\n",
    "        self.pin = pin\n",
    "        self.slice = self.m // self.k\n",
    "        self.a = bitarray(m)\n",
    "        self.a.setall(False)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.a[i]\n",
    "\n",
    "    def __setitem__(self, i, v):\n",
    "        self.a[i] = v\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.a.to01()\n",
    "\n",
    "    def __and__(self, other):\n",
    "        if self.m != other.m or self.k != other.k:\n",
    "            raise Exception('Operation error',\n",
    "                            'Length of bloom filters does not match.')\n",
    "        c = BloomFilter(self.m, self.k, self.pin)\n",
    "        # for i in range(self.m):\n",
    "        #\tc.a[i] = self.a[i] & other.a[i]\n",
    "        c.a = self.a & other.a\n",
    "        return c\n",
    "\n",
    "    def __or__(self, other):\n",
    "        if self.m != other.m or self.k != other.k:\n",
    "            raise Exception('Operation error',\n",
    "                            'Length of bloom filters does not match.')\n",
    "        c = BloomFilter(self.m, self.k, self.pin)\n",
    "        # for i in range(self.m):\n",
    "        #\tc.a[i] = self.a[i] | other.a[i]\n",
    "        c.a = self.a | other.a\n",
    "        return c\n",
    "\n",
    "    def __xor__(self, other):\n",
    "        if self.m != other.m or self.k != other.k:\n",
    "            raise Exception('Operation error',\n",
    "                            'Length of bloom filters does not match.')\n",
    "        c = BloomFilter(self.m, self.k, self.pin)\n",
    "        c.a = self.a ^ other.a\n",
    "        return c\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        base = self.h(item)\n",
    "        added = self.g(item)\n",
    "        for i in range(1, self.k + 1):\n",
    "            index = ((base + i * added) % self.slice) + (i - 1) * self.slice\n",
    "            if self.a[index] == False:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def h(self, x):\n",
    "        return int.from_bytes(sha512(x).digest(), byteorder='big')\n",
    "    \n",
    "    def g(self, x):\n",
    "        return int.from_bytes(hmac.new(pin, x, sha512).digest(), byteorder='big')\n",
    "\n",
    "    def additem(self, item):\n",
    "        base = self.h(item)\n",
    "        added = self.g(item)\n",
    "        for i in range(1, self.k + 1):\n",
    "            index = ((base + i * added) % self.slice) + (i - 1) * self.slice\n",
    "            self.a[index] = True\n",
    "\n",
    "    def addall(self, items):\n",
    "        for item in items:\n",
    "            self.additem(item)\n",
    "\n",
    "    def to_base64(self):\n",
    "        return urlsafe_b64encode(self.a.tobytes())\n",
    "\n",
    "    def ones(self):\n",
    "        return self.a.count(True)\n",
    "\n",
    "    def zeros(self):\n",
    "        return self.a.count(False)\n",
    "\n",
    "    def or_ones(self, other):\n",
    "        return (self | other).ones()\n",
    "\n",
    "    def or_zeros(self, other):\n",
    "        return (self | other).zeros()\n",
    "\n",
    "    def and_ones(self, other):\n",
    "        return (self & other).ones()\n",
    "\n",
    "    def and_zeros(self, other):\n",
    "        return (self & other).zeros()\n",
    "\n",
    "    def xor_ones(self, other):\n",
    "        return (self ^ other).ones()\n",
    "\n",
    "    def xor_zeros(self, other):\n",
    "        return (self ^ other).zeros()\n",
    "\n",
    "    def encoded_estimate(self):\n",
    "        return int(floor(- (self.m / self.k) * log(1 - self.ones() / self.m)))\n",
    "\n",
    "    def intersection_encoded_estimate(self, other):\n",
    "        return self.encoded_estimate() + other.encoded_estimate() - self.union_encoded_estimate(other)\n",
    "\n",
    "    def union_encoded_estimate(self, other):\n",
    "        return int(floor(- (self.m / self.k) * log(1 - self.or_ones(other) / self.m)))\n",
    "\n",
    "    def jaccard(self, other):\n",
    "        return self.intersection_encoded_estimate(other) / self.union_encoded_estimate(other)\n",
    "\n",
    "    def jaccard_distance(self, other):\n",
    "        return 1.0 - self.intersection_encoded_estimate(other) / self.union_encoded_estimate(other)\n",
    "\n",
    "    def tanimoto(self, other):\n",
    "        return self.and_ones(other) / self.or_ones(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T22:43:51.864895Z",
     "start_time": "2020-05-02T22:43:51.805939Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def emd(a, b):\n",
    "    d = 0\n",
    "    s = 0\n",
    "    for i in range(len(a)):\n",
    "        d = a[i] - b[i] + d\n",
    "        s = s + abs(d)\n",
    "    return s\n",
    "\n",
    "def emd_bloom(f, g):\n",
    "    d = f.encoded_estimate() + g.encoded_estimate() -2*f.intersection_encoded_estimate(g)\n",
    "    return d\n",
    "\n",
    "def dist(a, b):\n",
    "    s = 0\n",
    "    for i in range(len(a)):\n",
    "        s = abs(a[i] - b[i])\n",
    "    return s\n",
    "\n",
    "#We are converting to grayscale\n",
    "def gs_histogram(p, bins, integral):\n",
    "    a = np.array(Image.open(p).convert('L')).flatten()\n",
    "    b = np.histogram(a, bins)[0]\n",
    "    b = np.floor((b / np.sum(b)) * integral)\n",
    "    return b.astype(np.int16)\n",
    "\n",
    "def accumulative_histogram(fl):\n",
    "    return np.cumsum(fl)\n",
    "    \n",
    "def feature_list_rescale(fl, factor):\n",
    "    return [int(floor(x*factor)) for x in fl]\n",
    "\n",
    "def build_db(icons):\n",
    "    db = {}\n",
    "    for icon in icons:\n",
    "        db[icon] = gs_feature_list(icon)\n",
    "    return db\n",
    "\n",
    "def build_db_bloom(icons, bins, m, k, integral, pin):\n",
    "    db = {}\n",
    "    for icon in tqdm(icons):\n",
    "        b = gs_histogram(icon, bins, integral)\n",
    "        b = accumulative_histogram(b)\n",
    "        bf = BloomFilter(m,k,pin)\n",
    "        bf.addall(expand(b))\n",
    "        db[icon] = bf\n",
    "    return db\n",
    "\n",
    "def search(icon, db, comp, distance):\n",
    "    fl = feature_list(icon)\n",
    "    return [k for k,v in db.items() if comp(fl,v) <= distance]\n",
    "\n",
    "def search_db_bloom(icon, bins, m, k, integral, pin, db, distance):\n",
    "    b = gs_histogram(icon, bins, integral)\n",
    "    b = accumulative_histogram(b)\n",
    "    bf = BloomFilter(m,k,pin)\n",
    "    bf.addall(expand(b))\n",
    "    \n",
    "    return [(k,emd_bloom(bf,v)) for k,v in db.items() if emd_bloom(bf,v) <= distance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate database with images from http://www.vision.caltech.edu/Image_Datasets/Caltech101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T22:52:08.624980Z",
     "start_time": "2020-05-02T22:51:51.146065Z"
    }
   },
   "outputs": [],
   "source": [
    "db_size = 1024\n",
    "all_images = glob.glob('./101_ObjectCategories/*/*.jpg')\n",
    "icons = all_images[:db_size]\n",
    "bins = 16\n",
    "m = 8000\n",
    "k = 4\n",
    "factor = 100\n",
    "pin = b'1010'\n",
    "db = build_db_bloom(icons, bins, m, k, factor, pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute pairwise distances in the clear and using Bloom filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T22:45:28.638782Z",
     "start_time": "2020-05-02T22:44:32.655071Z"
    }
   },
   "outputs": [],
   "source": [
    "d_clear = np.zeros((db_size,db_size)).astype(np.int16)\n",
    "d_bloom = np.zeros((db_size,db_size)).astype(np.int16)\n",
    "\n",
    "clear_histos = []\n",
    "for i in tqdm(range(len(icons))):\n",
    "    clear_histos.append(gs_histogram(icons[i], 16, 100))\n",
    "\n",
    "for i in tqdm(range(len(icons))):\n",
    "    for j in range(i,len(icons)):\n",
    "        d_clear[i,j] = emd(clear_histos[i], clear_histos[j])\n",
    "d_clear = d_clear + d_clear.T - (d_clear*np.eye(db_size))\n",
    "\n",
    "for i in tqdm(range(len(icons))):\n",
    "    for j in range(i,len(icons)):\n",
    "        d_bloom[i,j] = emd_bloom(db[icons[i]],db[icons[j]])\n",
    "d_bloom = d_bloom + d_bloom.T - (d_bloom*np.eye(db_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T22:48:54.831655Z",
     "start_time": "2020-05-02T22:48:54.821655Z"
    }
   },
   "outputs": [],
   "source": [
    "mae = np.abs(d_clear - d_bloom).mean()\n",
    "display(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:23:39.907023Z",
     "start_time": "2020-05-02T23:23:39.476419Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.imshow(d_clear,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:23:54.253534Z",
     "start_time": "2020-05-02T23:23:53.834914Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.imshow(d_bloom,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single database search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 0\n",
    "print(all_images[0])\n",
    "print(search_db_bloom(all_images[0], bins, m, k, factor, pin, db, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for all images to check for false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:52:34.222409Z",
     "start_time": "2020-05-02T23:47:48.222573Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = []\n",
    "for image in tqdm(all_images):\n",
    "    matches.append(len(search_db_bloom(image, bins, m, k, factor, pin, db, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:53:34.496330Z",
     "start_time": "2020-05-02T23:53:34.487341Z"
    }
   },
   "outputs": [],
   "source": [
    "found = (np.argwhere(np.array(matches)>1))\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
